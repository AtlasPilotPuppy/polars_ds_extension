{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f4422-5c3a-4bd6-abe0-a15edfc62abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars_ds as pld\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef5c69-fff3-4779-9b58-f939d725f0b0",
   "metadata": {},
   "source": [
    "# Num Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fec01-5d0b-422f-b099-c86037512b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10_000\n",
    "df = pl.DataFrame({\n",
    "    \"f\": np.sin(list(range(size)))\n",
    "    , \"time_idx\": range(size)\n",
    "    , \"dummy\": [\"a\"] * (size // 2) + [\"b\"] * (size // 2)\n",
    "    , \"a\": np.random.random(size = size)\n",
    "    , \"b\": np.random.random(size = size)\n",
    "    , \"x1\" : range(size)\n",
    "    , \"x2\" : range(size, size + size)\n",
    "    , \"y\": range(-size, 0)\n",
    "    , \"actual\": np.round(np.random.random(size=size)).astype(np.int32)\n",
    "    , \"predicted\": np.random.random(size=size)\n",
    "    , \"dummy_groups\":[\"a\"] * (size//2) + [\"b\"] * (size//2) \n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f98453-34cd-4afc-b35d-db58fa60a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column-wise Jaccard Similarity. Result should be 0 as they are distinct\n",
    "df.select(\n",
    "    pl.col(\"x1\").num.jaccard(pl.col(\"x2\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d5346-e75b-4769-a953-e898d6a4d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT. First is real part, second is complex part\n",
    "df.select(\n",
    "    pl.col(\"f\").num.rfft()\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47b643-6bcc-43f6-9a25-82168c33e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least Square (Linear Regression)\n",
    "df.select(\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6da23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pl.col(\"y\").num.lstsq_report(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        add_bias = False\n",
    "    ).alias(\"report\")\n",
    ").unnest(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lazy().select(\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False)\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16511624-fc7f-45fc-b28e-ad9a91c1bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False).over(pl.col(\"dummy\"))\n",
    ").head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want prediction and residue instead of coefficients\n",
    "df.select(\n",
    "    \"x1\",\n",
    "    \"x2\",\n",
    "    \"y\",\n",
    "    (pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False, return_pred=True)).alias(\"prediction\")\n",
    ").unnest(\"prediction\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9fb061-340d-423d-9107-772387006ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"dummy\").agg(\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ff27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling regression\n",
    "df.lazy().rolling(\n",
    "    index_column = pl.col(\"time_idx\").set_sorted(),\n",
    "    period = \"30i\",\n",
    "    # offset = \"-1i\"\n",
    ").agg(\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False).alias(\"coefficients\")\n",
    ").slice(offset = 30).select(\n",
    "    \"time_idx\",\n",
    "    \"coefficients\",\n",
    ").collect().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fda8ca-57e7-4e02-a3f0-283ecce66a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Entropy, should be 0 because x1 is an ID\n",
    "df.select(\n",
    "    pl.col(\"y\").num.cond_entropy(pl.col(\"x1\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0d094-3c4c-4230-a589-1027c5690162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"dummy_groups\").agg(\n",
    "    pl.col(\"actual\").metric.l2_loss(pl.col(\"predicted\")).alias(\"l2\"),\n",
    "    pl.col(\"actual\").metric.bce(pl.col(\"predicted\")).alias(\"log loss\"),\n",
    "    pl.col(\"actual\").metric.binary_metrics_combo(pl.col(\"predicted\")).alias(\"combo\")\n",
    ").unnest(\"combo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7c6e3-0f1d-45f0-9fdb-cdb303b98556",
   "metadata": {},
   "source": [
    "# Str Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad36f9-264e-4a49-bf36-936639440edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100_000\n",
    "df2 = pl.DataFrame({\n",
    "    \"sen\":[\"Hello, world! I'm going to church.\"] * size,\n",
    "    \"word\":[\"words\", \"word\"] * (size //2)\n",
    "})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee123a7e-7f9b-4f48-a5d5-6354799201ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "df2.select(\n",
    "    pl.col(\"sen\").str.to_lowercase().str2.tokenize().explode().unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33017e3-17df-498b-93d9-1d656a344388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    pl.col(\"sen\").str.to_lowercase().str2.tokenize(stem=True).explode().unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69237c02-5f9f-4e92-b68d-6ac43aad1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    pl.col(\"word\").str2.levenshtein(\"world\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damerau-Levenshtein\n",
    "df2.select(\n",
    "    pl.col(\"word\").str2.d_levenshtein(\"world\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    pl.col(\"word\").str2.levenshtein(\"world\", return_sim = True)\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad7633-67fa-47f3-b86a-9f4cd097a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.filter(\n",
    "    # This is way faster than computing ditance and then doing a filter\n",
    "    pl.col(\"word\").str2.levenshtein_filter(\"world\", 1) # <= 1. \n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9477c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"word\":[\"apple\", \"banana\", \"pineapple\", \"asasasas\", \"sasasass\"],\n",
    "    \"other_data\": [1,2,3,4,5]\n",
    "})\n",
    "gibberish = [\"asasasa\", \"sasaaasss\", \"asdasadadfa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50591e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    pl.col(\"word\").str2.similar_to_vocab(\n",
    "        vocab = gibberish,\n",
    "        threshold = 0.5,\n",
    "        metric = \"lv\", # Levenshtein similarity. Other options: dleven, osa, jw\n",
    "        strategy = \"any\" # True if the word is similar to any word in vocab. Other options: \"all\", \"avg\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select(\n",
    "    pl.col(\"word\").str2.levenshtein(\"asasasa\", return_sim=True).alias(\"asasasa\"),\n",
    "    pl.col(\"word\").str2.levenshtein(\"sasaaasss\", return_sim=True).alias(\"sasaaasss\"),\n",
    "    pl.col(\"word\").str2.levenshtein(\"asdasadadfa\", return_sim=True).alias(\"asdasadadfa\"),\n",
    "    pl.col(\"word\").str2.fuzz(\"apples\").alias(\"LCS based Fuzz match - apples\"),\n",
    "    pl.col(\"word\").str2.osa(\"apples\", return_sim = True).alias(\"Optimal String Alignment - apples\"),\n",
    "    pl.col(\"word\").str2.jw(\"apples\").alias(\"Jaro-Winkler - apples\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pl.DataFrame({\n",
    "    \"a\": [None, None] + list(np.random.normal(size = 998))\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate random sample, respecting null positions in reference column (pl.col(\"a\"))\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.sample_normal(mean = 0.5, std = 1., respect_null=True).alias(\"random\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate random string\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.rand_str(min_size = 1, max_size = 5, respect_null=True).alias(\"random_str\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate fixed size random string\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.rand_str(min_size = 5, max_size = 5, respect_null=True).alias(\"random_str\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    # Sample from normal distribution, using reference column \"a\" 's mean and std\n",
    "    pl.col(\"a\").stats.sample_normal().alias(\"test1\") \n",
    "    # Sample from uniform distribution, with low = 0 and high = \"a\"'s max, and respect the nulls in \"a\"\n",
    "    , pl.col(\"a\").stats.sample_uniform(low = 0., high = None, respect_null=True).alias(\"test2\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate 2 random sample, both normally distributed\n",
    "# Run Welch's t test on them, p value should be big since they have equal mean\n",
    "# Run a normality test. Again, p value should be big since they are normally distributed \n",
    "\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.sample_normal(mean = 0.5, std = 1.).alias(\"test1\")\n",
    "    , pl.col(\"a\").stats.sample_normal(mean = 0.5, std = 2.).alias(\"test2\")\n",
    ").select(\n",
    "    pl.col(\"test1\").stats.ttest_ind(pl.col(\"test2\"), equal_var = False).alias(\"t-test\")\n",
    "    , pl.col(\"test1\").stats.normal_test().alias(\"normality_test\")\n",
    ").select(\n",
    "    pl.col(\"t-test\").struct.field(\"statistic\").alias(\"t-tests: statistics\")\n",
    "    , pl.col(\"t-test\").struct.field(\"pvalue\").alias(\"t-tests: pvalue\")\n",
    "    , pl.col(\"normality_test\").struct.field(\"statistic\").alias(\"normality_test: statistics\")\n",
    "    , pl.col(\"normality_test\").struct.field(\"pvalue\").alias(\"normality_test: pvalue\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5000\n",
    "df = pl.DataFrame({\n",
    "    \"market_id\": range(size),\n",
    "    \"group1\": np.random.random(size=size),\n",
    "    \"group2\": np.random.random(size=size),\n",
    "    \"category_1\": np.random.randint(low=0, high=5, size=size),\n",
    "    \"category_2\":np.random.randint(low=0, high=10, size=size)\n",
    "}).with_columns(\n",
    "    pl.col(\"market_id\").mod(3)\n",
    ")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In dataframe statistical tests!\n",
    "print(df.select(\n",
    "    pl.col(\"group1\").stats.ttest_ind(pl.col(\"group2\"), equal_var = True).alias(\"t-test\"),\n",
    "    pl.col(\"category_1\").stats.chi2(pl.col(\"category_2\")).alias(\"chi2-test\"),\n",
    "    pl.col(\"category_1\").stats.f_test(pl.col(\"group1\")).alias(\"f-test\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also be done in group by context\n",
    "df.group_by(\"market_id\").agg(\n",
    "    pl.col(\"group1\").stats.ttest_ind(pl.col(\"group2\"), equal_var = False).alias(\"t-test\"),\n",
    "    pl.col(\"category_1\").stats.chi2(pl.col(\"category_2\")).alias(\"chi2-test\"),-\n",
    "    pl.col(\"category_1\").stats.f_test(pl.col(\"group1\")).alias(\"f-test\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232e4d7",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Related Tasks\n",
    "\n",
    "These queries can be very slow when data/dimension gets huge, even when processed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aff1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars_ds as pld\n",
    "df = pl.DataFrame({\n",
    "    \"id\": range(1000),\n",
    "    \"val1\": np.random.random(size=1000), \n",
    "    \"val2\": np.random.random(size=1000), \n",
    "    \"val3\": np.random.random(size=1000),\n",
    "    \"r\": np.random.random(size=1000),\n",
    "    \"rh\": np.random.random(size=1000)*10,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neighbor count. The point itself is always considered a neighbor to itself.\n",
    "df.with_columns(\n",
    "    pld.query_nb_cnt(\n",
    "        0.1, # radius \n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), pl.col(\"val3\"), # Columns used as the coordinates in n-d space\n",
    "        dist = \"inf\", # L Infinity distance \n",
    "        parallel = True \n",
    "    ).alias(\"nb_l_inf_0_1_cnt\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    pld.query_nb_cnt(\n",
    "        pl.col(\"r\"), # radius be an expression too\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), pl.col(\"val3\"), # Columns used as the coordinates in n-d space\n",
    "        dist = \"l1\", # L 1 distance \n",
    "        parallel = True \n",
    "    ).alias(\"nb_l1_r_cnt\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids of the k nearest neighbors. \n",
    "# The point itself is always considered a neighbor to itself, so k + 1 elements will be returned.\n",
    "df.with_columns(\n",
    "    pl.col(\"id\").num.knn_ptwise(\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), pl.col(\"val3\"), # Columns used as the coordinates in n-d space\n",
    "        k = 3, \n",
    "        dist = \"l2\", # actually this is squared l2\n",
    "        parallel = True\n",
    "    ).alias(\"best friends\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a769f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all neighbors within radius r\n",
    "# The point itself is always considered a neighbor to itself.\n",
    "df.with_columns(\n",
    "    pl.col(\"id\").num.query_radius_ptwise(\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), pl.col(\"val3\"), # Columns used as the coordinates in n-d space\n",
    "        r = 0.1, \n",
    "        dist = \"l2\", # actually this is squared l2\n",
    "        parallel = True\n",
    "    ).list.slice(offset = 1).alias(\"best friends\"),\n",
    ").with_columns( # -1 to remove the point itself\n",
    "    (pl.col(\"best friends\").list.len() - 1).alias(\"best friends count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids of the k nearest neighbors and distances\n",
    "# The point itself is always considered a neighbor to itself, so k + 1 elements will be returned.\n",
    "df.with_columns(\n",
    "    pl.col(\"id\").num.knn_ptwise(\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), pl.col(\"val3\"), # Columns used as the coordinates in n-d space\n",
    "        k = 3, \n",
    "        dist = \"l2\", # actually this is squared l2\n",
    "        parallel = True,\n",
    "        return_dist = True\n",
    "    ).alias(\"best_friends_w_dist\")\n",
    ").unnest(\"best_friends_w_dist\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c69ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only points near the given point\n",
    "df.filter(\n",
    "    pld.query_radius(\n",
    "        [0.5, 0.5, 0.5],\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), pl.col(\"val3\"), # Columns used as the coordinates in n-d space\n",
    "        radius = 0.2,\n",
    "        dist = \"l2\" # actually this is squared l2, so this is asking for squared l2 <= 0.2\n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine distance is available when dimension is 2\n",
    "df.filter(\n",
    "    pld.query_radius(\n",
    "        [0.5, 0.5],\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), # Columns used as the coordinates in n-d space\n",
    "        radius = 10, # in km\n",
    "        dist = \"h\" \n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    pld.query_radius(\n",
    "        [0.5, 0.5],\n",
    "        # Columns used as the coordinates in n-d space\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), \n",
    "        # radius can also be an existing column in the dataframe.\n",
    "        radius = pl.col(\"rh\"), \n",
    "        dist = \"h\" \n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef172df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f8eabf1",
   "metadata": {},
   "source": [
    "# String Nearest Neighbors\n",
    "\n",
    "This might be slow for very large vocab / column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"a\":[\"AAAAA\", \"ABCABC\", \"AAAADDD\", \"ADSDSDS\", \"WORD\"],\n",
    "    \"b\":[\"AAAAT\", \"ABCACD\", \"ADSSD\", \"APPLES\", \"WORLD\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062fd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Levenshtein to find the nearest neighbor in vocab to word in column a\n",
    "df.select(\n",
    "    pl.col(\"a\").str2.similar_words(\n",
    "        vocab = pl.col(\"b\"),\n",
    "        k = 1,\n",
    "        metric = \"lv\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29437b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Levenshtein to find 2 nearest neighbors\n",
    "df.select(\n",
    "    pl.col(\"a\").str2.similar_words(\n",
    "        vocab = pl.col(\"b\"),\n",
    "        k = 2,\n",
    "        metric = \"lv\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9150bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently only Levenshtein and hamming are implemented for this\n",
    "# Empty means nothing in vocab can be compared in the hamming sense with the corresponding word in a\n",
    "df.select(\n",
    "    pl.col(\"a\").str2.similar_words(\n",
    "        vocab = pl.col(\"b\"),\n",
    "        k = 2,\n",
    "        threshold = 4, # <= threshold hamming distance away\n",
    "        metric = \"hamming\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35776a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may provide a vocab like this\n",
    "df.select(\n",
    "    pl.col(\"a\"),\n",
    "    pl.col(\"a\").str2.similar_words(\n",
    "        vocab = [\"WORLD\", \"AAAAA\", \"ABCDEFG\", \"ZIV\", \"TQQQ\"],\n",
    "        k = 3,\n",
    "        metric = \"lv\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f442e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
