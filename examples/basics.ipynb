{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f4422-5c3a-4bd6-abe0-a15edfc62abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars_ds as pds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a314316",
   "metadata": {},
   "source": [
    "# This notebook illustrates the basic usage of this package\n",
    "\n",
    "You need to create an environment with this package installed to run this notebook. (usually latest version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef5c69-fff3-4779-9b58-f939d725f0b0",
   "metadata": {},
   "source": [
    "# Num Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fec01-5d0b-422f-b099-c86037512b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10_000\n",
    "df = pl.DataFrame({\n",
    "    \"f\": np.sin(list(range(size)))\n",
    "    , \"time_idx\": range(size)\n",
    "    , \"dummy\": [\"a\"] * (size // 2) + [\"b\"] * (size // 2)\n",
    "    , \"a\": np.random.random(size = size)\n",
    "    , \"b\": np.random.random(size = size)\n",
    "    , \"x1\" : range(size)\n",
    "    , \"x2\" : range(size, size + size)\n",
    "    , \"y\": range(-size, 0)\n",
    "    , \"actual\": np.round(np.random.random(size=size)).astype(np.int32)\n",
    "    , \"predicted\": np.random.random(size=size)\n",
    "    , \"dummy_groups\":[\"a\"] * (size//2) + [\"b\"] * (size//2) \n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f98453-34cd-4afc-b35d-db58fa60a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column-wise Jaccard Similarity. Result should be 0 as they are distinct\n",
    "df.select(\n",
    "    pds.query_jaccard_col(\"x1\", pl.col(\"x2\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d5346-e75b-4769-a953-e898d6a4d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT. First is real part, second is complex part\n",
    "# By default, this behaves the same as np's rfft, which returns a non-redundant \n",
    "# compact representation of fft output.\n",
    "df.select(\n",
    "    pds.rfft(\"f\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c76353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT. But return the full length\n",
    "df.select(\n",
    "    pds.rfft(\"f\", return_full=True)\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6662d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution (by FFT). \n",
    "# Modes: `same`, `left` (left-aligned same), `right` (right-aligned same), `valid` or `full`\n",
    "# Currently slower than SciPy but provides parallelism because of Polars\n",
    "df.select(\n",
    "    pds.convolve(\"f\", [-1, 0, 0, 0, 1], mode = \"full\"),\n",
    "    pds.convolve(\"a\", [-1, 0, 0, 0, 1], mode = \"full\"),\n",
    "    pds.convolve(\"b\", [-1, 0, 0, 0, 1], mode = \"full\"),\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47b643-6bcc-43f6-9a25-82168c33e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least Square (Linear Regression)\n",
    "df.select(\n",
    "    pds.query_lstsq(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        target = pl.col(\"y\"),\n",
    "        add_bias=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6da23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pds.query_lstsq_report(\n",
    "        # str | pl.Expr\n",
    "        \"x1\", \"x2\",\n",
    "        target = pl.col(\"y\"),\n",
    "        add_bias=False\n",
    "    ).alias(\"report\")\n",
    ").unnest(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lazy().select(\n",
    "    pds.query_lstsq(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        target = \"y\", # We can either put pl.col(\"y\") here or just the string \"y\"\n",
    "        add_bias=False\n",
    "    )\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16511624-fc7f-45fc-b28e-ad9a91c1bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    \"dummy\",\n",
    "    pds.query_lstsq(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        target = pl.col(\"y\"),\n",
    "        add_bias=False\n",
    "    ).over(pl.col(\"dummy\"))\n",
    ").head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want prediction and residue instead of coefficients\n",
    "df.select(\n",
    "    \"x1\",\n",
    "    \"x2\",\n",
    "    \"y\",\n",
    "    pds.query_lstsq(\n",
    "        \"x1\", pl.col(\"x2\"),\n",
    "        target = \"y\",\n",
    "        add_bias=False, \n",
    "        return_pred=True\n",
    "    ).alias(\"prediction\")\n",
    ").unnest(\"prediction\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9fb061-340d-423d-9107-772387006ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"dummy\").agg(\n",
    "    pds.query_lstsq(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        target = pl.col(\"y\"),\n",
    "        add_bias=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ff27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling regression, kind of slow rn\n",
    "df.lazy().rolling(\n",
    "    index_column = pl.col(\"time_idx\").set_sorted(),\n",
    "    period = \"30i\",\n",
    "    # offset = \"-1i\"\n",
    ").agg(\n",
    "    pds.query_lstsq(pl.col(\"x1\"), pl.col(\"x2\"), target = pl.col(\"y\"), add_bias=False).alias(\"coefficients\")\n",
    ").slice(offset = 30).select(\n",
    "    \"time_idx\",\n",
    "    \"coefficients\",\n",
    ").collect().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fda8ca-57e7-4e02-a3f0-283ecce66a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Entropy, should be 0 because x1 is an ID\n",
    "df.select(\n",
    "    pds.query_cond_entropy(\"y\", \"x1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81def1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only want singular values (principal values?)\n",
    "df.select(\n",
    "    pds.query_singular_values(\"a\", \"b\", \"x1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc497383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular values + The principal components\n",
    "df.select(\n",
    "    pds.query_pca(\"a\", \"b\")\n",
    ").unnest(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e036f",
   "metadata": {},
   "source": [
    "# ML Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0d094-3c4c-4230-a589-1027c5690162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"dummy_groups\").agg(\n",
    "    pds.query_l2(\"actual\", \"predicted\").alias(\"l2\"),\n",
    "    pds.query_log_loss(\"actual\", \"predicted\").alias(\"log loss\"),\n",
    "    pds.query_binary_metrics(actual=\"actual\", pred=\"predicted\").alias(\"combo\")\n",
    ").unnest(\"combo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7c6e3-0f1d-45f0-9fdb-cdb303b98556",
   "metadata": {},
   "source": [
    "# Str Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad36f9-264e-4a49-bf36-936639440edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100_000\n",
    "df2 = pl.DataFrame({\n",
    "    \"sen\":[\"Hello, world! I'm going to church.\"] * size,\n",
    "    \"word\":[\"words\", \"word\"] * (size //2)\n",
    "})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee123a7e-7f9b-4f48-a5d5-6354799201ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "df2.select(\n",
    "    pds.str_tokenize(pl.col(\"sen\").str.to_lowercase()).explode().unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33017e3-17df-498b-93d9-1d656a344388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    pds.str_tokenize(pl.col(\"sen\").str.to_lowercase(), stem=True).explode().unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69237c02-5f9f-4e92-b68d-6ac43aad1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    pds.str_leven(\"word\", \"world\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damerau-Levenshtein\n",
    "df2.select(\n",
    "    pds.str_d_leven(\"word\", \"world\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795396dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select( # column \"word\" vs. the word \"world\"\n",
    "    pds.str_leven(\"word\", \"world\", return_sim = True)\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad7633-67fa-47f3-b86a-9f4cd097a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.filter(\n",
    "    # This is way faster than computing ditance and then doing a filter\n",
    "    pds.filter_by_levenshtein(pl.col(\"word\"), \"world\", 1) # <= 1. \n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9477c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"word\":[\"apple\", \"banana\", \"pineapple\", \"asasasas\", \"sasasass\"],\n",
    "    \"other_data\": [1,2,3,4,5]\n",
    "})\n",
    "gibberish = [\"asasasa\", \"sasaaasss\", \"asdasadadfa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50591e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    pds.similar_to_vocab(\n",
    "        pl.col(\"word\"),\n",
    "        vocab = gibberish,\n",
    "        threshold = 0.5,\n",
    "        metric = \"lv\", # Levenshtein similarity. Other options: dleven, osa, jw\n",
    "        strategy = \"any\" # True if the word is similar to any word in vocab. Other options: \"all\", \"avg\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pds.str_leven(\"word\", \"asasasa\", return_sim=True).alias(\"asasasa\"),\n",
    "    pds.str_leven(\"word\", \"sasaaasss\", return_sim=True).alias(\"sasaaasss\"),\n",
    "    pds.str_leven(\"word\", \"asdasadadfa\", return_sim=True).alias(\"asdasadadfa\"),\n",
    "    pds.str_fuzz(\"word\", \"apples\").alias(\"LCS based Fuzz match - apples\"),\n",
    "    pds.str_osa(\"word\", \"apples\", return_sim=True).alias(\"Optimal String Alignment - apples\"),\n",
    "    pds.str_jw(\"word\", \"apples\").alias(\"Jaro-Winkler - apples\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841f2a1",
   "metadata": {},
   "source": [
    "# Stats Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6171b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pl.DataFrame({\n",
    "    \"a\": [None, None] + list(np.random.normal(size = 998))\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate random numbers, respecting null positions in reference column (pl.col(\"a\"))\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.rand_normal(mean = 0.5, std = 1., respect_null=True).alias(\"random\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e13f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate random string\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.rand_str(min_size = 1, max_size = 5, respect_null=True).alias(\"random_str\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c37394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate fixed size random string, while respecting column a's nulls\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.rand_str(min_size = 5, max_size = 5, respect_null=True).alias(\"random_str\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    # Sample from a normal distribution, using reference column \"a\" 's mean and std\n",
    "    pl.col(\"a\").stats.rand_normal().alias(\"test1\") \n",
    "    # Sample from uniform distribution, with low = 0 and high = \"a\"'s max, and respect the nulls in \"a\"\n",
    "    , pl.col(\"a\").stats.rand_uniform(low = 0., high = None, respect_null=True).alias(\"test2\")\n",
    ").with_columns(\n",
    "    # Add a random pertubation to test1\n",
    "    pds.perturb(\"test1\", epsilon=0.001).alias(\"test1_perturbed\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New in v0.3.5\n",
    "# This way, we don't have a reference column, so we cannot respect nulls, but is more convenient to use.\n",
    "df.with_columns(\n",
    "    pds.random().alias(\"[0, 1)\"),\n",
    "    pds.random_normal(pl.col(\"a\").mean(), pl.col(\"a\").std()).alias(\"Normal\"),\n",
    "    pds.random_int(0, 10).alias(\"Int from [0, 10)\"),\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate 2 random sample, both normally distributed\n",
    "# Run Welch's t test on them, p value should be big since they have equal mean\n",
    "# Run a normality test. Again, p value should be big since they are normally distributed \n",
    "\n",
    "df.with_columns(\n",
    "    pds.random_normal(0.5, 1.0).alias(\"test1\"),\n",
    "    pds.random_normal(0.5, 2.0).alias(\"test2\"),\n",
    ").select(\n",
    "    pds.query_ttest_ind(\"test1\", \"test2\", equal_var=False).alias(\"t-test\"),\n",
    "    pds.normal_test(\"test1\").alias(\"normality_test\")\n",
    ").select(\n",
    "    pl.col(\"t-test\").struct.field(\"statistic\").alias(\"t-tests: statistics\")\n",
    "    , pl.col(\"t-test\").struct.field(\"pvalue\").alias(\"t-tests: pvalue\")\n",
    "    , pl.col(\"normality_test\").struct.field(\"statistic\").alias(\"normality_test: statistics\")\n",
    "    , pl.col(\"normality_test\").struct.field(\"pvalue\").alias(\"normality_test: pvalue\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5_000\n",
    "df = pl.DataFrame({\n",
    "    \"market_id\": range(size),\n",
    "}).with_columns(\n",
    "    pl.col(\"market_id\").mod(3),\n",
    "    var1 = pds.random(),\n",
    "    var2 = pds.random(),\n",
    "    category_1 = pds.random_int(0, 5),\n",
    "    category_2 = pds.random_int(0, 10),\n",
    ")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In dataframe statistical tests!\n",
    "df.select(\n",
    "    pds.query_ttest_ind(\"var1\", \"var2\", equal_var=True).alias(\"t-test\"),\n",
    "    pds.query_chi2(\"category_1\", \"category_2\").alias(\"chi2-test\"),\n",
    "    pds.query_f_test(\"var1\", group = \"category_1\").alias(\"f-test\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also be done in group by context\n",
    "df.group_by(\"market_id\").agg(\n",
    "    pds.query_ttest_ind(\"var1\", \"var2\", equal_var=False).alias(\"t-test\"),\n",
    "    pds.query_chi2(\"category_1\", \"category_2\").alias(\"chi2-test\"),\n",
    "    pds.query_f_test(\"var1\", group = \"category_1\").alias(\"f-test\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232e4d7",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Related Tasks\n",
    "\n",
    "These queries can be very slow when data/dimension gets huge, even when processed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aff1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars_ds as pds\n",
    "size = 2000\n",
    "df = pl.DataFrame({\n",
    "    \"id\": range(size), \n",
    "}).with_columns(\n",
    "    pds.random().alias(\"var1\"),\n",
    "    pds.random().alias(\"var2\"),\n",
    "    pds.random().alias(\"var3\"),\n",
    "    pds.random().alias(\"r\"),\n",
    "    (pds.random() * 10).alias(\"rh\"),\n",
    "    pl.col(\"id\").cast(pl.UInt32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neighbor count. The point itself is always considered a neighbor to itself.\n",
    "df.with_columns(\n",
    "    pds.query_nb_cnt(\n",
    "        0.1, # radius \n",
    "        pl.col(\"var1\"), \"var2\", \"var3\", # Columns used as the coordinates in n-d space, str | pl.Expr \n",
    "        dist = \"inf\", # L Infinity distance \n",
    "        parallel = True \n",
    "    ).alias(\"nb_l_inf_cnt\")\n",
    ").head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    pds.query_nb_cnt(\n",
    "        pl.col(\"r\"), # radius be an expression too\n",
    "        \"var1\", \"var2\", \"var3\", # Columns used as the coordinates in n-d space, str | pl.Expr \n",
    "        dist = \"l1\", # L 1 distance \n",
    "        parallel = True \n",
    "    ).alias(\"nb_l1_r_cnt\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids of the k nearest neighbors. \n",
    "# The point itself is always considered a neighbor to itself, so k + 1 elements will be returned.\n",
    "df.with_columns(\n",
    "    pds.query_knn_ptwise(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), pl.col(\"var3\"), # Columns used as the coordinates in n-d space\n",
    "        index = \"id\",  # pl.col(\"id\"), str | pl.Expr\n",
    "        k = 3, \n",
    "        dist = \"l2\", # squared l2\n",
    "        parallel = True\n",
    "    ).alias(\"best friends\")\n",
    ").head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a769f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all neighbors within radius r\n",
    "# The point itself is always considered a neighbor to itself.\n",
    "print(df.select(\n",
    "    pl.col(\"id\"),\n",
    "    pds.query_radius_ptwise(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), pl.col(\"var3\"), # Columns used as the coordinates in n-d space\n",
    "        index = pl.col(\"id\"),\n",
    "        r = 0.1, \n",
    "        dist = \"l2\", # actually this is squared l2\n",
    "        parallel = True\n",
    "    ).alias(\"best friends\"),\n",
    ").with_columns( # -1 to remove the point itself\n",
    "    (pl.col(\"best friends\").list.len() - 1).alias(\"best friends count\")\n",
    ").head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids of the k nearest neighbors and distances\n",
    "# The point itself is always considered a neighbor to itself, so k + 1 elements will be returned.\n",
    "df.with_columns(\n",
    "    pds.query_knn_ptwise(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), pl.col(\"var3\"), # Columns used as the coordinates in n-d space\n",
    "        index = pl.col(\"id\"),\n",
    "        k = 3, \n",
    "        dist = \"l2\", # actually this is squared l2\n",
    "        parallel = True,\n",
    "        return_dist = True\n",
    "    ).alias(\"best_friends_w_dist\")\n",
    ").unnest(\"best_friends_w_dist\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c69ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only points near the given point\n",
    "df.filter(\n",
    "    pds.query_within_dist_from(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), pl.col(\"var3\"), # Columns used as the coordinates in n-d space\n",
    "        pt = [0.5, 0.5, 0.5],\n",
    "        r = 0.2,\n",
    "        dist = \"l2\" # actually this is squared l2, so this is asking for squared l2 <= 0.2\n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine distance is available when dimension is 2\n",
    "df.filter(\n",
    "    pds.query_within_dist_from(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), # Columns used as the coordinates in n-d space\n",
    "        pt = [0.5, 0.5],\n",
    "        r = 10, # in km\n",
    "        dist = \"h\" \n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    pds.query_within_dist_from(\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), \n",
    "        pt = [0.5, 0.5],\n",
    "        # radius can also be an existing column in the dataframe.\n",
    "        r = pl.col(\"rh\"), \n",
    "        dist = \"h\" \n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14627bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = df.select(\n",
    "    pl.col(\"id\").cast(pl.UInt64),\n",
    "    pds.query_radius_ptwise(\n",
    "        # Columns used as the coordinates in n-d space\n",
    "        pl.col(\"var1\"), pl.col(\"var2\"), \n",
    "        index=pl.col(\"id\"),\n",
    "        r = 0.02, \n",
    "        dist = \"l2\",\n",
    "    ).alias(\"friends\")\n",
    ").with_columns(\n",
    "    pl.col(\"friends\").list.len().alias(\"count\")\n",
    ")\n",
    "friends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e4400",
   "metadata": {},
   "source": [
    "# Simple Graph Queries\n",
    "\n",
    "There is limited functionality in the Graph module currently. E.g. Only constant cost per edge.\n",
    "\n",
    "Graph queries are very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# friends.select(\n",
    "#     pl.col(\"friends\").graph.eigen_centrality() # .arg_max()\n",
    "# ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn friends to a table suitable for graph analytics\n",
    "df_graph = friends.select(\n",
    "    pl.col(\"id\"),\n",
    "    pl.col(\"friends\"),\n",
    ").explode(pl.col(\"friends\")).with_columns(\n",
    "    pl.col(\"id\").cast(pl.UInt32),\n",
    "    pl.col(\"friends\").cast(pl.UInt32),\n",
    ")\n",
    "df_graph.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph.select(\n",
    "    # Shortest path to the node with id = 3\n",
    "    # Node and link can be str | pl.Expr\n",
    "    pds.query_shortest_path(node = \"id\", link = pl.col(\"friends\"), target = 3, cost = None, parallel=True).alias(\"shortest_path\")\n",
    ").unnest(\"shortest_path\").sort(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d43fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph.select(\n",
    "    # Almost every node can reach node 3, and the number is the number steps to reach it\n",
    "    # This is a way faster way to filter results if you don't need the actual path\n",
    "    pds.query_node_reachable(\"id\", \"friends\", target = 3).alias(\"reach\")\n",
    ").unnest(\"reach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships = pl.DataFrame({\n",
    "    \"id\": range(5),\n",
    "    \"connections\":[[1,2,3,4], [2,3], [4], [0,1,2], [1]],\n",
    "    # Small values means closer\n",
    "    \"close-ness\":[[0.4, 0.3, 0.2, 0.1], [0.1, 1.0], [0.5], [0.1, 0.1, 0.1], [0.1]]\n",
    "}).with_columns(\n",
    "    pl.col(\"id\").cast(pl.UInt32),\n",
    "    pl.col(\"connections\").list.eval(pl.element().cast(pl.UInt32))\n",
    ").explode(\n",
    "    pl.col(\"connections\"), pl.col(\"close-ness\")\n",
    ")\n",
    "\n",
    "relationships.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239f4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To go to node at id = 1, node 0 would rather go to 4 first and then 1.\n",
    "relationships.select(\n",
    "    pds.query_shortest_path(\"id\", \"connections\", target = 1, cost = \"close-ness\").alias(\"path\")\n",
    ").unnest(\"path\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df458bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In and out deg\n",
    "relationships.select(\n",
    "    pds.query_node_deg(\"id\", \"connections\", directed=True).alias(\"deg\")\n",
    ").unnest(\"deg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8eabf1",
   "metadata": {},
   "source": [
    "# String Nearest Neighbors\n",
    "\n",
    "This might be very slow for very large vocab / column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"a\":[\"AAAAA\", \"ABCABC\", \"AAAADDD\", \"ADSDSDS\", \"WORD\"],\n",
    "    \"b\":[\"AAAAT\", \"ABCACD\", \"ADSSD\", \"APPLES\", \"WORLD\"] \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062fd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Levenshtein to find the nearest neighbor in vocab to word in column a\n",
    "df.select(\n",
    "    pds.query_similar_words(\n",
    "        \"a\",\n",
    "        vocab = pl.col(\"b\"),\n",
    "        k = 1, \n",
    "        metric = \"lv\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29437b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Levenshtein to find 2 nearest neighbors\n",
    "df.select(\n",
    "    pds.query_similar_words(\n",
    "        \"a\",\n",
    "        vocab = pl.col(\"b\"),\n",
    "        k = 2, \n",
    "        metric = \"lv\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9150bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently only Levenshtein and hamming are implemented for this\n",
    "# Empty means nothing in vocab can be compared in the hamming sense with the corresponding word in a\n",
    "df.select(\n",
    "    pds.query_similar_words(\n",
    "        \"a\",\n",
    "        vocab = pl.col(\"b\"),\n",
    "        k = 2, \n",
    "        threshold = 4,\n",
    "        metric = \"hamming\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35776a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may provide a vocab like this\n",
    "df.select(\n",
    "    pl.col(\"a\"),\n",
    "    pds.query_similar_words(\n",
    "        \"a\",\n",
    "        vocab = [\"WORLD\", \"AAAAA\", \"ABCDEFG\", \"ZIV\", \"TQQQ\"],\n",
    "        k = 3, \n",
    "        metric = \"lv\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42a771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
