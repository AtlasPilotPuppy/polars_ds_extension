{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529f4422-5c3a-4bd6-abe0-a15edfc62abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars_ds as pld\n",
    "import polars as pl\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef5c69-fff3-4779-9b58-f939d725f0b0",
   "metadata": {},
   "source": [
    "# Num Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430fec01-5d0b-422f-b099-c86037512b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>f</th><th>time_idx</th><th>dummy</th><th>a</th><th>b</th><th>x1</th><th>x2</th><th>y</th><th>actual</th><th>predicted</th><th>dummy_groups</th></tr><tr><td>f64</td><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i32</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>0.0</td><td>0</td><td>&quot;a&quot;</td><td>0.779889</td><td>0.017166</td><td>0</td><td>10000</td><td>-10000</td><td>1</td><td>0.516704</td><td>&quot;a&quot;</td></tr><tr><td>0.841471</td><td>1</td><td>&quot;a&quot;</td><td>0.22455</td><td>0.385061</td><td>1</td><td>10001</td><td>-9999</td><td>0</td><td>0.810815</td><td>&quot;a&quot;</td></tr><tr><td>0.909297</td><td>2</td><td>&quot;a&quot;</td><td>0.486951</td><td>0.290885</td><td>2</td><td>10002</td><td>-9998</td><td>0</td><td>0.989207</td><td>&quot;a&quot;</td></tr><tr><td>0.14112</td><td>3</td><td>&quot;a&quot;</td><td>0.362267</td><td>0.854708</td><td>3</td><td>10003</td><td>-9997</td><td>0</td><td>0.323271</td><td>&quot;a&quot;</td></tr><tr><td>-0.756802</td><td>4</td><td>&quot;a&quot;</td><td>0.802233</td><td>0.913961</td><td>4</td><td>10004</td><td>-9996</td><td>0</td><td>0.75938</td><td>&quot;a&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌───────────┬──────────┬───────┬──────────┬───┬────────┬────────┬───────────┬──────────────┐\n",
       "│ f         ┆ time_idx ┆ dummy ┆ a        ┆ … ┆ y      ┆ actual ┆ predicted ┆ dummy_groups │\n",
       "│ ---       ┆ ---      ┆ ---   ┆ ---      ┆   ┆ ---    ┆ ---    ┆ ---       ┆ ---          │\n",
       "│ f64       ┆ i64      ┆ str   ┆ f64      ┆   ┆ i64    ┆ i32    ┆ f64       ┆ str          │\n",
       "╞═══════════╪══════════╪═══════╪══════════╪═══╪════════╪════════╪═══════════╪══════════════╡\n",
       "│ 0.0       ┆ 0        ┆ a     ┆ 0.779889 ┆ … ┆ -10000 ┆ 1      ┆ 0.516704  ┆ a            │\n",
       "│ 0.841471  ┆ 1        ┆ a     ┆ 0.22455  ┆ … ┆ -9999  ┆ 0      ┆ 0.810815  ┆ a            │\n",
       "│ 0.909297  ┆ 2        ┆ a     ┆ 0.486951 ┆ … ┆ -9998  ┆ 0      ┆ 0.989207  ┆ a            │\n",
       "│ 0.14112   ┆ 3        ┆ a     ┆ 0.362267 ┆ … ┆ -9997  ┆ 0      ┆ 0.323271  ┆ a            │\n",
       "│ -0.756802 ┆ 4        ┆ a     ┆ 0.802233 ┆ … ┆ -9996  ┆ 0      ┆ 0.75938   ┆ a            │\n",
       "└───────────┴──────────┴───────┴──────────┴───┴────────┴────────┴───────────┴──────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 10_000\n",
    "df = pl.DataFrame({\n",
    "    \"f\": np.sin(list(range(size)))\n",
    "    , \"time_idx\": range(size)\n",
    "    , \"dummy\": [\"a\"] * (size // 2) + [\"b\"] * (size // 2)\n",
    "    , \"a\": np.random.random(size = size)\n",
    "    , \"b\": np.random.random(size = size)\n",
    "    , \"x1\" : range(size)\n",
    "    , \"x2\" : range(size, size + size)\n",
    "    , \"y\": range(-size, 0)\n",
    "    , \"actual\": np.round(np.random.random(size=size)).astype(np.int32)\n",
    "    , \"predicted\": np.random.random(size=size)\n",
    "    , \"dummy_groups\":[\"a\"] * (size//2) + [\"b\"] * (size//2) \n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f98453-34cd-4afc-b35d-db58fa60a69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x1</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌─────┐\n",
       "│ x1  │\n",
       "│ --- │\n",
       "│ f64 │\n",
       "╞═════╡\n",
       "│ 0.0 │\n",
       "└─────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column-wise Jaccard Similarity. Result should be 0 as they are distinct\n",
    "df.select(\n",
    "    pl.col(\"x1\").num.jaccard(pl.col(\"x2\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416d5346-e75b-4769-a953-e898d6a4d84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>f</th></tr><tr><td>list[f64]</td></tr></thead><tbody><tr><td>[1.939505, 0.0]</td></tr><tr><td>[1.939506, 0.000209]</td></tr><tr><td>[1.939508, 0.000418]</td></tr><tr><td>[1.939512, 0.000627]</td></tr><tr><td>[1.939518, 0.000835]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌──────────────────────┐\n",
       "│ f                    │\n",
       "│ ---                  │\n",
       "│ list[f64]            │\n",
       "╞══════════════════════╡\n",
       "│ [1.939505, 0.0]      │\n",
       "│ [1.939506, 0.000209] │\n",
       "│ [1.939508, 0.000418] │\n",
       "│ [1.939512, 0.000627] │\n",
       "│ [1.939518, 0.000835] │\n",
       "└──────────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FFT. First is real part, second is complex part\n",
    "df.select(\n",
    "    pl.col(\"f\").num.rfft()\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed47b643-6bcc-43f6-9a25-82168c33e7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>y</th></tr><tr><td>list[f64]</td></tr></thead><tbody><tr><td>[2.0, -1.0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌─────────────┐\n",
       "│ y           │\n",
       "│ ---         │\n",
       "│ list[f64]   │\n",
       "╞═════════════╡\n",
       "│ [2.0, -1.0] │\n",
       "└─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Least Square (Linear Regression)\n",
    "df.select(\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e6da23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>feat_idx</th><th>coeff</th><th>std_err</th><th>t</th><th>p&gt;|t|</th></tr><tr><td>u16</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>2.0</td><td>2.3854e-16</td><td>8.3842e15</td><td>0.0</td></tr><tr><td>1</td><td>-1.0</td><td>9.0158e-17</td><td>-1.1092e16</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 5)\n",
       "┌──────────┬───────┬────────────┬────────────┬───────┐\n",
       "│ feat_idx ┆ coeff ┆ std_err    ┆ t          ┆ p>|t| │\n",
       "│ ---      ┆ ---   ┆ ---        ┆ ---        ┆ ---   │\n",
       "│ u16      ┆ f64   ┆ f64        ┆ f64        ┆ f64   │\n",
       "╞══════════╪═══════╪════════════╪════════════╪═══════╡\n",
       "│ 0        ┆ 2.0   ┆ 2.3854e-16 ┆ 8.3842e15  ┆ 0.0   │\n",
       "│ 1        ┆ -1.0  ┆ 9.0158e-17 ┆ -1.1092e16 ┆ 0.0   │\n",
       "└──────────┴───────┴────────────┴────────────┴───────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\n",
    "    pl.col(\"y\").num.lstsq_report(\n",
    "        pl.col(\"x1\"), pl.col(\"x2\"),\n",
    "        add_bias = False\n",
    "    ).alias(\"report\")\n",
    ").unnest(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>y</th></tr><tr><td>list[f64]</td></tr></thead><tbody><tr><td>[2.0, -1.0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌─────────────┐\n",
       "│ y           │\n",
       "│ ---         │\n",
       "│ list[f64]   │\n",
       "╞═════════════╡\n",
       "│ [2.0, -1.0] │\n",
       "└─────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lazy().select(\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False)\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16511624-fc7f-45fc-b28e-ad9a91c1bfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>coeffs</th></tr><tr><td>list[f64]</td></tr></thead><tbody><tr><td>[2.0, -1.0]</td></tr><tr><td>[2.0, -1.0]</td></tr><tr><td>[2.0, -1.0]</td></tr><tr><td>[2.0, -1.0]</td></tr><tr><td>[2.0, -1.0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌─────────────┐\n",
       "│ coeffs      │\n",
       "│ ---         │\n",
       "│ list[f64]   │\n",
       "╞═════════════╡\n",
       "│ [2.0, -1.0] │\n",
       "│ [2.0, -1.0] │\n",
       "│ [2.0, -1.0] │\n",
       "│ [2.0, -1.0] │\n",
       "│ [2.0, -1.0] │\n",
       "└─────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False).over(pl.col(\"dummy\"))\n",
    ").head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f550c7c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateError",
     "evalue": "column with name 'y' has more than one occurrences",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12359/569924151.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"x1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"x2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m ).unnest(\"pred\").head()\n\u001b[0m",
      "\u001b[0;32m~/Desktop/MY/Projects/polars_ds_extension/.venv/lib/python3.11/site-packages/polars/dataframe/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, columns, *more_columns)\u001b[0m\n\u001b[1;32m  10179\u001b[0m         \u001b[0;31m└\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m┴\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m┴\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m┴\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m┴\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m┴\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m─\u001b[0m\u001b[0;31m┘\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10181\u001b[0m         \"\"\"\n\u001b[1;32m  10182\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_expand_selectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmore_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_pydf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mDuplicateError\u001b[0m: column with name 'y' has more than one occurrences"
     ]
    }
   ],
   "source": [
    "# If you want prediction and residue instead of coefficients\n",
    "df.select(\n",
    "    \"x1\",\n",
    "    \"x2\",\n",
    "    \"y\",\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False, return_pred=True).alias(\"pred\")\n",
    ").unnest(\"pred\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9fb061-340d-423d-9107-772387006ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"dummy\").agg(\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ff27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling regression\n",
    "df.lazy().rolling(\n",
    "    index_column = pl.col(\"time_idx\").set_sorted(),\n",
    "    period = \"30i\",\n",
    "    # offset = \"-1i\"\n",
    ").agg(\n",
    "    pl.col(\"y\").num.lstsq(pl.col(\"x1\"), pl.col(\"x2\"), add_bias=False).alias(\"coefficients\")\n",
    ").slice(offset = 30).select(\n",
    "    \"time_idx\",\n",
    "    \"coefficients\",\n",
    ").collect().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fda8ca-57e7-4e02-a3f0-283ecce66a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Entropy, should be 0 because x1 is an ID\n",
    "df.select(\n",
    "    pl.col(\"y\").num.cond_entropy(pl.col(\"x1\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0d094-3c4c-4230-a589-1027c5690162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"dummy_groups\").agg(\n",
    "    pl.col(\"actual\").metric.l2_loss(pl.col(\"predicted\")).alias(\"l2\"),\n",
    "    pl.col(\"actual\").metric.bce(pl.col(\"predicted\")).alias(\"log loss\"),\n",
    "    pl.col(\"actual\").metric.binary_metrics_combo(pl.col(\"predicted\")).alias(\"combo\")\n",
    ").unnest(\"combo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7c6e3-0f1d-45f0-9fdb-cdb303b98556",
   "metadata": {},
   "source": [
    "# Str Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad36f9-264e-4a49-bf36-936639440edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100_000\n",
    "df2 = pl.DataFrame({\n",
    "    \"sen\":[\"Hello, world! I'm going to church.\"] * size,\n",
    "    \"word\":[\"words\", \"word\"] * (size //2)\n",
    "})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee123a7e-7f9b-4f48-a5d5-6354799201ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "df2.select(\n",
    "    pl.col(\"sen\").str.to_lowercase().str2.tokenize().explode().unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33017e3-17df-498b-93d9-1d656a344388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    pl.col(\"sen\").str.to_lowercase().str2.tokenize(stem=True).explode().unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69237c02-5f9f-4e92-b68d-6ac43aad1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    pl.col(\"word\").str2.levenshtein(\"world\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damerau-Levenshtein\n",
    "df2.select(\n",
    "    pl.col(\"word\").str2.d_levenshtein(\"world\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    pl.col(\"word\").str2.levenshtein(\"world\", return_sim = True)\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad7633-67fa-47f3-b86a-9f4cd097a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.filter(\n",
    "    # This is way faster than computing ditance and then doing a filter\n",
    "    pl.col(\"word\").str2.levenshtein_filter(\"world\", 1) # <= 1. \n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9477c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"word\":[\"apple\", \"banana\", \"pineapple\", \"asasasas\", \"sasasass\"],\n",
    "    \"other_data\": [1,2,3,4,5]\n",
    "})\n",
    "gibberish = [\"asasasa\", \"sasaaasss\", \"asdasadadfa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50591e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    pl.col(\"word\").str2.similar_to_vocab(\n",
    "        vocab = gibberish,\n",
    "        threshold = 0.5,\n",
    "        metric = \"lv\", # Levenshtein similarity. Other options: dleven, osa, jw\n",
    "        strategy = \"any\" # True if the word is similar to any word in vocab. Other options: \"all\", \"avg\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select(\n",
    "    pl.col(\"word\").str2.levenshtein(\"asasasa\", return_sim=True).alias(\"asasasa\"),\n",
    "    pl.col(\"word\").str2.levenshtein(\"sasaaasss\", return_sim=True).alias(\"sasaaasss\"),\n",
    "    pl.col(\"word\").str2.levenshtein(\"asdasadadfa\", return_sim=True).alias(\"asdasadadfa\"),\n",
    "    pl.col(\"word\").str2.fuzz(\"apples\").alias(\"LCS based Fuzz match - apples\"),\n",
    "    pl.col(\"word\").str2.osa(\"apples\", return_sim = True).alias(\"Optimal String Alignment - apples\"),\n",
    "    pl.col(\"word\").str2.jw(\"apples\").alias(\"Jaro-Winkler - apples\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pl.DataFrame({\n",
    "    \"a\": [None, None] + list(np.random.normal(size = 998))\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate random sample, respecting null positions in reference column (pl.col(\"a\"))\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.sample_normal(mean = 0.5, std = 1., respect_null=True).alias(\"random\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate random string\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.rand_str(min_size = 1, max_size = 5, respect_null=True).alias(\"random_str\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate fixed size random string\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.rand_str(min_size = 5, max_size = 5, respect_null=True).alias(\"random_str\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    # Sample from normal distribution, using reference column \"a\" 's mean and std\n",
    "    pl.col(\"a\").stats.sample_normal().alias(\"test1\") \n",
    "    # Sample from uniform distribution, with low = 0 and high = \"a\"'s max, and respect the nulls in \"a\"\n",
    "    , pl.col(\"a\").stats.sample_uniform(low = 0., high = None, respect_null=True).alias(\"test2\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate 2 random sample, both normally distributed\n",
    "# Run Welch's t test on them, p value should be big since they have equal mean\n",
    "# Run a normality test. Again, p value should be big since they are normally distributed \n",
    "\n",
    "df.with_columns(\n",
    "    pl.col(\"a\").stats.sample_normal(mean = 0.5, std = 1.).alias(\"test1\")\n",
    "    , pl.col(\"a\").stats.sample_normal(mean = 0.5, std = 2.).alias(\"test2\")\n",
    ").select(\n",
    "    pl.col(\"test1\").stats.ttest_ind(pl.col(\"test2\"), equal_var = False).alias(\"t-test\")\n",
    "    , pl.col(\"test1\").stats.normal_test().alias(\"normality_test\")\n",
    ").select(\n",
    "    pl.col(\"t-test\").struct.field(\"statistic\").alias(\"t-tests: statistics\")\n",
    "    , pl.col(\"t-test\").struct.field(\"pvalue\").alias(\"t-tests: pvalue\")\n",
    "    , pl.col(\"normality_test\").struct.field(\"statistic\").alias(\"normality_test: statistics\")\n",
    "    , pl.col(\"normality_test\").struct.field(\"pvalue\").alias(\"normality_test: pvalue\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5000\n",
    "df = pl.DataFrame({\n",
    "    \"market_id\": range(size),\n",
    "    \"group1\": np.random.random(size=size),\n",
    "    \"group2\": np.random.random(size=size),\n",
    "    \"category_1\": np.random.randint(low=0, high=5, size=size),\n",
    "    \"category_2\":np.random.randint(low=0, high=10, size=size)\n",
    "}).with_columns(\n",
    "    pl.col(\"market_id\").mod(3)\n",
    ")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In dataframe statistical tests!\n",
    "print(df.select(\n",
    "    pl.col(\"group1\").stats.ttest_ind(pl.col(\"group2\"), equal_var = True).alias(\"t-test\"),\n",
    "    pl.col(\"category_1\").stats.chi2(pl.col(\"category_2\")).alias(\"chi2-test\"),\n",
    "    pl.col(\"category_1\").stats.f_test(pl.col(\"group1\")).alias(\"f-test\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also be done in group by context\n",
    "df.group_by(\"market_id\").agg(\n",
    "    pl.col(\"group1\").stats.ttest_ind(pl.col(\"group2\"), equal_var = False).alias(\"t-test\"),\n",
    "    pl.col(\"category_1\").stats.chi2(pl.col(\"category_2\")).alias(\"chi2-test\"),-\n",
    "    pl.col(\"category_1\").stats.f_test(pl.col(\"group1\")).alias(\"f-test\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232e4d7",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Related Tasks\n",
    "\n",
    "These queries can be very slow when data/dimension gets huge, even when processed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aff1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars_ds as pld\n",
    "df = pl.DataFrame({\n",
    "    \"id\": range(1000),\n",
    "    \"val1\": np.random.random(size=1000), \n",
    "    \"val2\": np.random.random(size=1000), \n",
    "    \"val3\": np.random.random(size=1000),\n",
    "    \"r\": np.random.random(size=1000),\n",
    "    \"rh\": np.random.random(size=1000)*10,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neighbor count. The point itself is always considered a neighbor to itself.\n",
    "df.select(\n",
    "    pld.query_nb_cnt(\n",
    "        0.1, # radius \n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), pl.col(\"val3\"), # Columns used as the coordinates in n-d space\n",
    "        dist = \"inf\", # L Infinity distance \n",
    "        parallel = True \n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pld.query_nb_cnt(\n",
    "        pl.col(\"r\"), # radius be an expression too\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), pl.col(\"val3\"), # Columns used as the coordinates in n-d space\n",
    "        dist = \"l1\", # L 1 distance \n",
    "        parallel = True \n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids of the k nearest neighbors. \n",
    "# The point itself is always considered a neighbor to itself, so k + 1 elements will be returned.\n",
    "df.with_columns(\n",
    "    pl.col(\"id\").num.knn_ptwise(\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), pl.col(\"val3\"), # Columns used as the coordinates in n-d space\n",
    "        k = 3, \n",
    "        dist = \"l2\", # actually this is squared l2\n",
    "        parallel = True\n",
    "    ).alias(\"best friends\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c69ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only points near the given point\n",
    "df.filter(\n",
    "    pld.query_radius(\n",
    "        [0.5, 0.5, 0.5],\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), pl.col(\"val3\"), # Columns used as the coordinates in n-d space\n",
    "        radius = 0.2,\n",
    "        dist = \"l2\" # actually this is squared l2, so this is asking for squared l2 <= 0.2\n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine distance is available when dimension is 2\n",
    "df.filter(\n",
    "    pld.query_radius(\n",
    "        [0.5, 0.5],\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), # Columns used as the coordinates in n-d space\n",
    "        radius = 10, # in km\n",
    "        dist = \"h\" \n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    pld.query_radius(\n",
    "        [0.5, 0.5],\n",
    "        # Columns used as the coordinates in n-d space\n",
    "        pl.col(\"val1\"), pl.col(\"val2\"), \n",
    "        # radius can also be an existing column in the dataframe.\n",
    "        radius = pl.col(\"rh\"), \n",
    "        dist = \"h\" \n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef172df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f8eabf1",
   "metadata": {},
   "source": [
    "# String Nearest Neighbors\n",
    "\n",
    "This might be slow for very large vocab / column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"a\":[\"AAAAA\", \"ABCABC\", \"AAAADDD\", \"ADSDSDS\", \"WORD\"],\n",
    "    \"b\":[\"AAAAT\", \"ABCACD\", \"ADSSD\", \"APPLES\", \"WORLD\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062fd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Levenshtein to find the nearest neighbor in vocab to word in column a\n",
    "df.select(\n",
    "    pl.col(\"a\").str2.similar_words(\n",
    "        vocab = pl.col(\"b\"),\n",
    "        k = 1,\n",
    "        metric = \"lv\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29437b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Levenshtein to find 2 nearest neighbors\n",
    "df.select(\n",
    "    pl.col(\"a\").str2.similar_words(\n",
    "        vocab = pl.col(\"b\"),\n",
    "        k = 2,\n",
    "        metric = \"lv\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9150bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently only Levenshtein and hamming are implemented for this\n",
    "# Empty means nothing in vocab can be compared in the hamming sense with the corresponding word in a\n",
    "df.select(\n",
    "    pl.col(\"a\").str2.similar_words(\n",
    "        vocab = pl.col(\"b\"),\n",
    "        k = 2,\n",
    "        threshold = 4, # <= threshold hamming distance away\n",
    "        metric = \"hamming\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35776a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may provide a vocab like this\n",
    "df.select(\n",
    "    pl.col(\"a\"),\n",
    "    pl.col(\"a\").str2.similar_words(\n",
    "        vocab = [\"WORLD\", \"AAAAA\", \"ABCDEFG\", \"ZIV\", \"TQQQ\"],\n",
    "        k = 3,\n",
    "        metric = \"lv\"\n",
    "    ).alias(\"similar_words_from_vocab\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84936fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
