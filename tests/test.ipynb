{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars_ds as pds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"a\": [1, None, 2, 3],\n",
    "    \"b\": [3, None, None, 3]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars_ds.transforms as t\n",
    "\n",
    "df.with_columns(\n",
    "    t.impute(df, cols = [\"a\", \"b\"], method = \"mean\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "mat = imputer.fit_transform(df.to_pandas())\n",
    "pl.from_numpy(mat, schema=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = df.to_pandas()\n",
    "y = df_pd[\"target\"]\n",
    "cols = [\"cat\"]\n",
    "enc = TargetEncoder(min_samples_leaf= 20, smoothing = 10.0, cols = cols)\n",
    "enc.fit(df_pd[cols], y)\n",
    "df_transformed = enc.transform(df_pd[cols])\n",
    "df_2 = pl.from_pandas(df_transformed[cols])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars_ds.transforms as t\n",
    "\n",
    "df.select(\n",
    "    t.target_encode(df, [\"cat\"], target = \"target\", min_samples_leaf = 20, smoothing = 10.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\"../examples/dependency.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polars_ds.pipeline import Pipeline\n",
    "import polars.selectors as cs\n",
    "\n",
    "# df.select(pl.col(\"Existing_EMI\"))\n",
    "\n",
    "pipe = (\n",
    "    Pipeline(df)\n",
    "    .lowercase() # lowercase all columns\n",
    "    .impute([\"existing_emi\"], method = \"median\")\n",
    "    .select(cs.numeric() | cs.by_name([\"gender\", \"employer_category1\"]))\n",
    "    .append_expr([\n",
    "        pl.col(\"existing_emi\").log1p().alias(\"existing_emi_log1p\"),\n",
    "        pl.col(\"loan_amount\").log1p().alias(\"loan_amount_log1p\"),\n",
    "        pl.col(\"loan_amount\").sqrt().alias(\"loan_amount_sqrt\"),\n",
    "    ])\n",
    "    .scale(\n",
    "        cs.numeric().exclude([\"var1\", \"existing_emi_log1p\"]), method = \"standard\"\n",
    "    ) # Scale the columns up to this point. The columns below won't be scaled\n",
    "    .append_expr(\n",
    "        pl.col(\"employer_category1\").is_null().cast(pl.UInt8).alias(\"gender_is_missing\")\n",
    "    )\n",
    "    .one_hot_encode(\"gender\", drop_first=True)\n",
    "    .target_encode(\"employer_category1\", target = \"approved\", min_samples_leaf = 20, smoothing = 10.0)\n",
    "    .finish() # or .fit()\n",
    ")\n",
    "\n",
    "pipe.transform(return_lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pds.random_data(size=100_000, n_cols = 0).select(\n",
    "    pds.random_int(0, 200).alias(\"x\"),\n",
    "    pds.random_int(0, 200).alias(\"y\"),\n",
    "    pl.Series([1] * 50_000 + [2] * 50_000).alias(\"test\")\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pds.query_lstsq_report(\"x\", target=\"y\", add_bias=True).alias(\"report\")\n",
    ")[\"report\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pl.col(\"x\").qcut(10, left_closed=False, allow_duplicates=True, include_breaks=True)\n",
    "        .struct.field(\"brk\")\n",
    "        .value_counts()\n",
    "        .sort()\n",
    ").unnest(\"brk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pl.corr(\"x\", \"y\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select(\n",
    "    pds.kendall_tau(\"x\", \"y\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "x = df[\"x\"].to_numpy()\n",
    "y = df[\"y\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "kendalltau(x,y, nan_policy=\"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(pl.col(\"x\").rank(method=\"random\")).select(\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    pl.col(\"y\").rank(method=\"max\").cast(pl.Float64).alias(\"r\"),\n",
    "    (-pl.col(\"y\")).rank(method=\"max\").cast(pl.Float64).alias(\"l\"),\n",
    ").with_columns(\n",
    "    pl.col(\"r\").diff().abs().alias(\"r_abs_diff\"),\n",
    "    (pl.col(\"l\") * (pl.len() - pl.col(\"l\"))).alias(\"l(n-l)\"),\n",
    ").select(\n",
    "    1 - (pl.len() / 2) * (pl.col(\"r_abs_diff\").sum() / pl.col(\"l(n-l)\").sum())\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
